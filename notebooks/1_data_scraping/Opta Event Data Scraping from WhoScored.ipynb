{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "colonial-clear",
   "metadata": {},
   "source": [
    "<a id='top'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-linux",
   "metadata": {},
   "source": [
    "# Opta Event Data Scraping from WhoScored? \n",
    "##### Notebook to scrape raw Opta Event data by StatsPerform from [WhoScored?](https://www.whoscored.com/), using [ScraperFC](https://github.com/oseymour/ScraperFC) by [Owen Seymour](https://mobile.twitter.com/owen_seymour)\n",
    "\n",
    "### By [Edd Webster](https://www.twitter.com/eddwebster)\n",
    "Notebook first written: 08/12/2021<br>\n",
    "Notebook last updated: 08/12/2021\n",
    "\n",
    "![Stats Perform](../../img/logos/stats_perform_logo_small.png)\n",
    "\n",
    "![Opta](../../img/logos/opta_sports_logo_small.png)\n",
    "\n",
    "![WhoScored?](../../img/logos/whoscored-logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-conditioning",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a id='sectionintro'></a>\n",
    "\n",
    "## <a id='import_libraries'>Introduction</a>\n",
    "This notebook scrapes player Event data from [WhoScored?](https://www.whoscored.com/) using the [ScraperFC](https://github.com/oseymour/ScraperFC) library by [Owen Seymour](https://mobile.twitter.com/owen_seymour), [pandas](http://pandas.pydata.org/) for data manipulation through DataFrames, and [Selenium](https://www.selenium.dev/) and [Beautifulsoup](https://pypi.org/project/beautifulsoup4/) for webscraping.\n",
    "\n",
    "For more information about this notebook and the author, I'm available through all the following channels:\n",
    "*    [eddwebster.com](https://www.eddwebster.com/);\n",
    "*    edd.j.webster@gmail.com;\n",
    "*    [@eddwebster](https://www.twitter.com/eddwebster);\n",
    "*    [linkedin.com/in/eddwebster](https://www.linkedin.com/in/eddwebster/);\n",
    "*    [github/eddwebster](https://github.com/eddwebster/);\n",
    "*    [public.tableau.com/profile/edd.webster](https://public.tableau.com/profile/edd.webster);\n",
    "*    [kaggle.com/eddwebster](https://www.kaggle.com/eddwebster); and\n",
    "*    [hackerrank.com/eddwebster](https://www.hackerrank.com/eddwebster).\n",
    "\n",
    "![Edd Webster](../../img/fifa21eddwebsterbanner.png)\n",
    "\n",
    "The accompanying GitHub repository for this notebook can be found [here](https://github.com/eddwebster/football_analytics) and a static version of this notebook can be found [here](https://nbviewer.jupyter.org/github/eddwebster/football_analytics/blob/master/notebooks/1_data_scraping/Capology%20Player%20Salary%20Web%20Scraping.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-hamburg",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a id='sectioncontents'></a>\n",
    "\n",
    "## <a id='notebook_contents'>Notebook Contents</a>\n",
    "1.    [Notebook Dependencies](#section1)<br>\n",
    "2.    [Project Brief](#section2)<br>\n",
    "3.    [Data Scraping](#section3)<br>\n",
    "      1.    [Introduction](#section3.1)<br>\n",
    "      2.    [Scrape Data by League and Season](#section3.2)<br>\n",
    "4.    [Summary](#section4)<br>\n",
    "5.    [Next Steps](#section5)<br>\n",
    "6.    [References](#section6)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-nerve",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a id='section1'></a>\n",
    "\n",
    "## <a id='#section1'>1. Notebook Dependencies</a>\n",
    "\n",
    "This notebook was written using [Python 3](https://docs.python.org/3.7/) and requires the following libraries:\n",
    "*    [`Jupyter notebooks`](https://jupyter.org/) for this notebook environment with which this project is presented;\n",
    "*    [`NumPy`](http://www.numpy.org/) for multidimensional array computing;\n",
    "*    [`pandas`](http://pandas.pydata.org/) for data analysis and manipulation;\n",
    "*    [`Beautifulsoup`](https://pypi.org/project/beautifulsoup4/) and [`Selenium`](https://www.selenium.dev/) for web scraping; and\n",
    "*    [`ScraperFC`](https://github.com/oseymour/ScraperFC) by [Owen Seymour](https://mobile.twitter.com/owen_seymour) (run pip install ScraperFC)\n",
    "\n",
    "All packages used for this notebook except for [Beautifulsoup](https://pypi.org/project/beautifulsoup4/) and [Selenium](https://www.selenium.dev/) can be obtained by downloading and installing the [Conda](https://anaconda.org/anaconda/conda) distribution, available on all platforms (Windows, Linux and Mac OSX). Step-by-step guides on how to install Anaconda can be found for Windows [here](https://medium.com/@GalarnykMichael/install-python-on-windows-anaconda-c63c7c3d1444) and Mac [here](https://medium.com/@GalarnykMichael/install-python-on-mac-anaconda-ccd9f2014072), as well as in the Anaconda documentation itself [here](https://docs.anaconda.com/anaconda/install/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-guess",
   "metadata": {},
   "source": [
    "### Import Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "defined-option",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 (ideally)\n",
    "import platform\n",
    "import sys, getopt\n",
    "assert sys.version_info >= (3, 5)\n",
    "import csv\n",
    "\n",
    "# Import Dependencies\n",
    "%matplotlib inline\n",
    "\n",
    "# Math Operations\n",
    "import numpy as np\n",
    "from math import pi\n",
    "\n",
    "# Datetime\n",
    "import datetime\n",
    "from datetime import date\n",
    "import time\n",
    "\n",
    "# Data Preprocessing\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import glob\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "\n",
    "# Reading directories\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Working with JSON\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "# Web Scraping\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "# ScraperFC library\n",
    "#import ScraperFC as sfc    # run pip install ScraperFC\n",
    "import traceback\n",
    "\n",
    "# Data Visualisation\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import missingno as msno\n",
    "\n",
    "# Progress Bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Display in Jupyter\n",
    "from IPython.display import Image, YouTubeVideo\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "# Ignore Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
    "\n",
    "print('Setup Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "confident-workstation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.7.6\n",
      "NumPy: 1.20.3\n",
      "pandas: 1.3.2\n",
      "matplotlib: 3.4.2\n"
     ]
    }
   ],
   "source": [
    "# Python / module versions used here for reference\n",
    "print('Python: {}'.format(platform.python_version()))\n",
    "print('NumPy: {}'.format(np.__version__))\n",
    "print('pandas: {}'.format(pd.__version__))\n",
    "print('matplotlib: {}'.format(mpl.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-report",
   "metadata": {},
   "source": [
    "### Defined Variables and Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-distributor",
   "metadata": {},
   "source": [
    "##### Today's Date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accurate-boston",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define today's date\n",
    "todays_date = datetime.datetime.now().strftime('%d/%m/%Y').replace('/', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590800e4",
   "metadata": {},
   "source": [
    "##### Lists of folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "129babad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lists of folders\n",
    "\n",
    "## Folders types\n",
    "lst_folders = ['raw', 'engineered']\n",
    "\n",
    "## League names\n",
    "lst_leagues = ['EPL', 'Bundesliga', 'Serie A', 'Ligue 1', 'Argentina Liga Profesional', 'EFL Championship', 'EFL1', 'EFL2']\n",
    "\n",
    "## Seasons\n",
    "lst_seasons = ['2009-2010', '2010-2011', '2011-2012', '2012-2013', '2013-2014', '2014-2015', '2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022']\n",
    "\n",
    "## Data types\n",
    "lst_data_types = ['events', 'formations', 'players']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "official-vault",
   "metadata": {},
   "source": [
    "### Defined Filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pretty-abortion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up initial paths to subfolders\n",
    "#base_dir = os.path.join('..', '..')\n",
    "base_dir = '/Volumes/3TB EXT/2022 work'    # alternative base dir when working from hard drive\n",
    "data_dir = os.path.join(base_dir, 'data')\n",
    "data_dir_opta = os.path.join(base_dir, 'data', 'opta')\n",
    "img_dir = os.path.join(base_dir, 'img')\n",
    "fig_dir = os.path.join(base_dir, 'img', 'fig')\n",
    "scripts_dir = os.path.join(base_dir, 'scripts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d745852",
   "metadata": {},
   "source": [
    "### Custom Libraries\n",
    "Import the scripts from the [ScraperFC](https://github.com/oseymour/ScraperFC) by [Owen Seymour](https://twitter.com/owen_seymour), stored in the 'ScraperFC' subfolder of the 'scripts' folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "870dd054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the customer ScraperFC libraries required tfor scraping data\n",
    "\n",
    "## Define the filepath of scripts - the 'ScraperFC' subfolder of the 'scripts' folder\n",
    "sys.path.insert(0, os.path.abspath(scripts_dir))\n",
    "\n",
    "## Custom scripts for scraping data created as part of the ScraperFC library by Owen Seymour\n",
    "import ScraperFC as sfc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-examination",
   "metadata": {},
   "source": [
    "### Custom Functions (Scrapers)\n",
    "Two different scrapers written as wrappers around [Owen Seymour](https://twitter.com/owen_seymour)'s code:\n",
    "1.    Single match (`scrape_whoscored_match`)\n",
    "2.    Entire season (`scrape_whoscored_season`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-palestine",
   "metadata": {},
   "source": [
    "#### Single Match Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f738a0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for scraping a full season of Event data from WhoScored\n",
    "def scrape_whoscored_match(url):\n",
    "\n",
    "    ## Initiate WhoScored scraper\n",
    "    scraper = sfc.WhoScored()\n",
    "    \n",
    "    ## \n",
    "    try:\n",
    "        data = scraper.scrape_match(url)\n",
    "\n",
    "    ## \n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "\n",
    "    ## Close WhoScored scraper\n",
    "    scraper.close()\n",
    "    \n",
    "    ## Return unified season dataset\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-copper",
   "metadata": {},
   "source": [
    "#### Full Season Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6e02983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for scraping a full season of Event data from WhoScored\n",
    "def scrape_whoscored_season(season, comp):\n",
    "\n",
    "    ## Initiate WhoScored scraper\n",
    "    scraper = sfc.WhoScored()\n",
    "    \n",
    "    ## \n",
    "    try:\n",
    "        data = scraper.scrape_matches(season, comp)\n",
    "\n",
    "    ## \n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "\n",
    "    ## Close WhoScored scraper\n",
    "    scraper.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456dbcce",
   "metadata": {},
   "source": [
    "### Create Directory Structure\n",
    "Create folders and subfolders for data, if not already created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adab81b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temoprary Directory sturcture used \n",
    "\n",
    "## Define list of folders\n",
    "lst_folders = ['events', 'formations', 'players']\n",
    "\n",
    "# Make the data directory structure\n",
    "for folder in lst_folders:\n",
    "    path = os.path.join(folder)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d0af2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the data directory structure\n",
    "for folder in lst_folders:\n",
    "    path = os.path.join(folder)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "        for league in lst_leagues:\n",
    "            league = league.replace(' ', '_').lower()\n",
    "            path = os.path.join(folder, league)\n",
    "            if not os.path.exists(path):\n",
    "                os.mkdir(path)\n",
    "                for season in lst_seasons:\n",
    "                    path = os.path.join(folder, league, season)\n",
    "                    if not os.path.exists(path):\n",
    "                        os.mkdir(path)\n",
    "                        for data_type in lst_data_types:\n",
    "                            path = os.path.join(folder, league, season, data_type)\n",
    "                            if not os.path.exists(path):\n",
    "                                os.mkdir(path)\n",
    "path = os.path.join('reference')\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "path = os.path.join('archive')\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-professor",
   "metadata": {},
   "source": [
    "### Notebook Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "distinct-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all columns of displayed pandas DataFrames\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-giving",
   "metadata": {},
   "source": [
    "## <a id='#section2'>2. Project Brief</a>\n",
    "This Jupyter notebook is part of a series of notebooks, to scrape, parse, engineer, and unify datasets, that can be used for modeling purposes.\n",
    "\n",
    "This particular notebook is one of several **web scraping** notebooks, that takes player salary data from the [WhoScored?](https://www.whoscored.com/), and scrapes it using [Selenium](https://www.selenium.dev/) and [Beautifulsoup](https://pypi.org/project/beautifulsoup4/) and manipulates it as Dataframes using [pandas](http://pandas.pydata.org/).\n",
    "\n",
    "This notebook, along with the other notebooks in this project workflow are shown in the following diagram:\n",
    "\n",
    "![roadmap](../../img/football_analytics_data_roadmap.png)\n",
    "\n",
    "Links to these notebooks in the [`football_analytics`](https://github.com/eddwebster/football_analytics) GitHub repository can be found at the following:\n",
    "*    [1. Webscraping](https://github.com/eddwebster/football_analytics/tree/master/notebooks/1_data_scraping)\n",
    "     +    [FBref Player Stats Webscraping](https://github.com/eddwebster/football_analytics/blob/master/notebooks/1_data_scraping/FBref%20Player%20Stats%20Web%20Scraping.ipynb)\n",
    "     +    [TransferMarket Player Bio and Status Webscraping](https://github.com/eddwebster/football_analytics/blob/master/notebooks/1_data_scraping/TransferMarkt%20Player%20Bio%20and%20Status%20Web%20Scraping.ipynb)\n",
    "     +    [TransferMarket Player Valuation Webscraping](https://github.com/eddwebster/football_analytics/blob/master/notebooks/1_data_scraping/TransferMarkt%20Player%20Valuation%20Web%20Scraping.ipynb)\n",
    "     +    [TransferMarkt Player Recorded Transfer Fees Webscraping](https://github.com/eddwebster/football_analytics/blob/master/notebooks/1_data_scraping/TransferMarkt%20Player%20Recorded%20Transfer%20Fees%20Webscraping.ipynb)\n",
    "     +    [Capology Player Salary Webscraping](https://github.com/eddwebster/football_analytics/blob/master/notebooks/1_data_scraping/Capology%20Player%20Salary%20Web%20Scraping.ipynb)\n",
    "     +    [FBref Team Stats Webscraping](https://github.com/eddwebster/football_analytics/blob/master/notebooks/1_data_scraping/FBref%20Team%20Stats%20Web%20Scraping.ipynb)\n",
    "     +    [WhoScored? Event Data Scraping]() \n",
    "*    [2. Data Parsing](https://github.com/eddwebster/football_analytics/tree/master/notebooks/2_data_parsing)\n",
    "     +    [ELO Team Ratings Data Parsing](https://github.com/eddwebster/football_analytics/blob/master/notebooks/2_data_parsing/ELO%20Team%20Ratings%20Data%20Parsing.ipynb)\n",
    "*    [3. Data Engineering](https://github.com/eddwebster/football_analytics/tree/master/notebooks/3_data_engineering)\n",
    "     +    [FBref Player Stats Data Engineering](https://github.com/eddwebster/football_analytics/blob/master/notebooks/3_data_engineering/FBref%20Player%20Stats%20Data%20Engineering.ipynb)\n",
    "     +    [TransferMarket Player Bio and Status Data Engineering](https://github.com/eddwebster/football_analytics/blob/master/notebooks/3_data_engineering/TransferMarkt%20Player%20Bio%20and%20Status%20Data%20Engineering.ipynb)\n",
    "     +    [TransferMarket Player Valuation Data Engineering](https://github.com/eddwebster/football_analytics/blob/master/notebooks/3_data_engineering/TransferMarkt%20Player%20Valuation%20Data%20Engineering.ipynb)\n",
    "     +    [TransferMarkt Player Recorded Transfer Fees Data Engineering](https://github.com/eddwebster/football_analytics/blob/master/notebooks/3_data_engineering/TransferMarkt%20Player%20Recorded%20Transfer%20Fees%20Data%20Engineering.ipynb)\n",
    "     +    [Capology Player Salary Data Engineering](https://github.com/eddwebster/football_analytics/blob/master/notebooks/3_data_engineering/Capology%20Player%20Salary%20Data%20Engineering.ipynb)\n",
    "     +    [FBref Team Stats Data Engineering](https://github.com/eddwebster/football_analytics/blob/master/notebooks/3_data_engineering/FBref%20Team%20Stats%20Data%20Engineering.ipynb)\n",
    "     +    [ELO Team Ratings Data Parsing](https://github.com/eddwebster/football_analytics/blob/master/notebooks/3_data_engineering/ELO%20Team%20Ratings%20Data%20Parsing.ipynb)\n",
    "     +    [TransferMarkt Team Recorded Transfer Fee Data Engineering](https://github.com/eddwebster/football_analytics/blob/master/notebooks/3_data_engineering/TransferMarkt%20Team%20Recorded%20Transfer%20Fee%20Data%20Engineering.ipynb) (aggregated from [TransferMarkt Player Recorded Transfer Fees notebook](https://github.com/eddwebster/football_analytics/blob/master/notebooks/3_data_engineering/TransferMarkt%20Player%20Recorded%20Transfer%20Fees%20Data%20Engineering.ipynb))\n",
    "     +    [Capology Team Salary Data Engineering](https://github.com/eddwebster/football_analytics/blob/master/notebooks/3_data_engineering/Capology%20Team%20Salary%20Data%20Engineering.ipynb) (aggregated from [Capology Player Salary notebook](https://github.com/eddwebster/football_analytics/blob/master/notebooks/3_data_engineering/Capology%20Player%20Salary%20Data%20Engineering.ipynb))\n",
    "     +    [WhoScored? Event Data Engineering]() \n",
    "*    [4. Data Unification](https://github.com/eddwebster/football_analytics/tree/master/notebooks/4_data_unification)\n",
    "*    [5. Modeling and Data Analysis]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-indicator",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='section3'></a>\n",
    "\n",
    "## <a id='#section3'>3. Data Scraping</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-charlotte",
   "metadata": {},
   "source": [
    "### <a id='#section3.1'>3.1. Introduction</a>\n",
    "Through WhoScored? Match Centre, it is possible to scrape Opta on-the-ball Event data for football matches from nearly twenty leagues, including the 'Big 5' European leagues, with some leagues going as far back as 2009/10 season.\n",
    "\n",
    "The following video demonstrates how to extract a single match of data manually. This notebook works per this logic, but in an automated manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "476a24df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed video of where Event data can be found in WhoScored!\n",
    "#Video('../../../../../video/demo/whoscored.mov', width=770, height=530)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feef6db3",
   "metadata": {},
   "source": [
    "This notebook scrapers the data with two different functions:\n",
    "1.    Single match (`scrape_whoscored_match`)\n",
    "2.    Entire season (`scrape_whoscored_season`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-boutique",
   "metadata": {},
   "source": [
    "### <a id='#section3.2'>3.2. Scrape Data by League and Season</a>\n",
    "The [ScraperFC](https://github.com/oseymour/ScraperFC) code creates links to individual matches in a season, provided the link to each link.\n",
    "\n",
    "The following leagues and competitions have been identified as using event data in the match center, so far. This may change and there may be competitions missed, but these are the ones identified so far.\n",
    "\n",
    "| No.     | League / Cup Competition| Country / Continent     | League Hyperlink    | Available to scrape (right now)   | Earliest season to scrape     |      \n",
    "|---------|-------------------------|-------------------------|---------------------|-----------------------------------|----------|\n",
    "| 1.      | EPL                     | England                 | https://www.whoscored.com/Regions/252/Tournaments/2/England-Premier-League     | Y    | 2009/2010     | \n",
    "| 2.      | La Liga                 | Spain                   | https://www.whoscored.com/Regions/206/Tournaments/4/Spain-LaLiga     | Y    | 2009/2010     |  \n",
    "| 3.      | Bundesliga              | Germany                 | https://www.whoscored.com/Regions/81/Tournaments/3/Germany-Bundesliga     | Y    |  2009/2010     | \n",
    "| 4.      | Serie A                 | Italy                   | https://www.whoscored.com/Regions/108/Tournaments/5/Italy-Serie-A     | Y    | 2009/2010     |  \n",
    "| 5.      | Ligue 1                 | France                  | https://www.whoscored.com/Regions/74/Tournaments/22/France-Ligue-1     | Y    | 2009/2010     |  \n",
    "| 6.      | Liga NOS                | Portugal                | https://www.whoscored.com/Regions/177/Tournaments/21/Portugal-Liga-NOS     | N     | 2016/2017     | \n",
    "| 7.      | Eredivisie              | Netherlands             | https://www.whoscored.com/Regions/155/Tournaments/13/Netherlands-Eredivisie     | N     | 2013/2014     | \n",
    "| 8.      | Premier League          | Russia                  | https://www.whoscored.com/Regions/182/Tournaments/77/Russia-Premier-League      | N     | 2013/2014     | \n",
    "| 9.      | Brasileirão             | Brazil                  | https://www.whoscored.com/Regions/31/Tournaments/95/Brazil-Brasileir%C3%A3o     | N     | 2013          | \n",
    "| 10.      | Major League Soccer     | USA                     | https://www.whoscored.com/Regions/233/Tournaments/85/USA-Major-League-Soccer     | N     | 2013          | \n",
    "| 11.      | Super Lig               | Turkey                  | https://www.whoscored.com/Regions/225/Tournaments/17/Turkey-Super-Lig     | N     | 2014/2015     | \n",
    "| 12.      | EFL Championship        | England                 | https://www.whoscored.com/Regions/252/Tournaments/7/England-Championship     | Y    | 2013/2014       | \n",
    "| 13.      | Premiership             | Scotland                | https://www.whoscored.com/Regions/253/Tournaments/20/Scotland-Premiership     | N     | 2020/2021     | \n",
    "| 14.      | EFL1                    | England                 | https://www.whoscored.com/Regions/252/Tournaments/8/England-League-One     | Y    | 2018/2019              |  \n",
    "| 15.      | EFL2                    | England                 | https://www.whoscored.com/Regions/252/Tournaments/9/England-League-Two     | Y    | 2018/2019              | \n",
    "| 16.      | Liga Profesional        | Argentina               | https://www.whoscored.com/Regions/11/Tournaments/68/Argentina-Liga-Profesional    | Y    | 2016          |  \n",
    "| 17.      | Jupiler Pro League      | Belgium                 | https://www.whoscored.com/Regions/22/Tournaments/18/Belgium-Jupiler-Pro-League     | N     | 2020/2021     |\n",
    "| 18.      | Bundesliga II           | Germany                 | https://www.whoscored.com/Regions/81/Tournaments/6/Germany-Bundesliga-II     | N     | 2015/2016     |\n",
    "| 19.      | Champions League        | Europe                  | https://www.whoscored.com/Regions/250/Tournaments/12/Europe-Champions-League     | N     | 2009/2010     |\n",
    "| 20.      | Europa League           | Europe                  | https://www.whoscored.com/Regions/250/Tournaments/30/Europe-Europa-League     | N     | 2012/2013     |\n",
    "| 21.      | FA Cup              | England    | https://www.whoscored.com/Regions/252/Tournaments/29/England-League-Cup     | N     | 2012/2013 (latter stages of the competition)    |\n",
    "| 22.      | League Cup              | England    | https://www.whoscored.com/Regions/252/Tournaments/29/England-League-Cup     | N     | 2012/2013 (latter stages of the competition)    |\n",
    "| 23.      | FIFA World Cup          | International    | https://www.whoscored.com/Regions/247/Tournaments/36/International-FIFA-World-Cup     | N     | 2014          |\n",
    "| 24.      | European Championship   | International (Europe)     | https://www.whoscored.com/Regions/247/Tournaments/124/International-European-Championship     | N     | 2012            |\n",
    "| 25.      | African Cup of Nations  | International (Africa)     | https://www.whoscored.com/Regions/247/Tournaments/104/International-Africa-Cup-of-Nations     | N     | 2021 (I think)              |\n",
    "\n",
    "Leagues that aren't available to scrape right now, can be with slight amendments to the ScraperFC scripts, they just haven't been done yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9470d40c",
   "metadata": {},
   "source": [
    "#### <a id='#section3.2.1'>3.2.1. Full Season Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f193156b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-09 12:43:48.993794: Scraping, engineering, and saving of the data for the Ligue 1 league for the 2021 season has now started...\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \r",
      "Scraping match data for match 1/380 in the 2020-2021 Ligue 1 season from https://www.whoscored.com/Matches/1464170/Live/France-Ligue-1-2020-2021-Brest-Lyon\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ScraperFC/WhoScored.py:340: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df_home_formations['playerIds'] = df_home_formations['playerIds'].str.replace('[','')\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ScraperFC/WhoScored.py:341: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df_home_formations['playerIds'] = df_home_formations['playerIds'].str.replace(']','')\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ScraperFC/WhoScored.py:351: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df_away_formations['playerIds'] = df_away_formations['playerIds'].str.replace('[','')\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ScraperFC/WhoScored.py:352: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df_away_formations['playerIds'] = df_away_formations['playerIds'].str.replace(']','')\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ScraperFC/WhoScored.py:728: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df_events['period'] = df_events['period'].str.replace('[','')\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ScraperFC/WhoScored.py:729: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df_events['type'] = df_events['type'].str.replace('[','')\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ScraperFC/WhoScored.py:730: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df_events['outcomeType'] = df_events['outcomeType'].str.replace('[','')\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ScraperFC/WhoScored.py:731: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df_events['qualifiers'] = df_events['qualifiers'].str.replace('[','')\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ScraperFC/WhoScored.py:732: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df_events['satisfiedEventsTypes'] = df_events['satisfiedEventsTypes'].str.replace('[','')\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ScraperFC/WhoScored.py:735: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df_events['period'] = df_events['period'].str.replace(']','')\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ScraperFC/WhoScored.py:736: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df_events['type'] = df_events['type'].str.replace(']','')\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ScraperFC/WhoScored.py:737: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df_events['outcomeType'] = df_events['outcomeType'].str.replace(']','')\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ScraperFC/WhoScored.py:738: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df_events['qualifiers'] = df_events['qualifiers'].str.replace(']','')\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ScraperFC/WhoScored.py:739: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df_events['satisfiedEventsTypes'] = df_events['satisfiedEventsTypes'].str.replace(']','')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data for 2021-02-19: Brest (2) vs. Lyon (3) in the Ligue 1 league for the 2021 season.\n",
      "Saving home formation data...\n",
      "Saving away formation data...\n",
      "Saving player data...\n",
      "Saving event data...\n",
      "Scraping, engineering, and saving of the data for the Ligue 1 league for the 2021 season is now complete\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \r",
      "Scraping match data for match 20/380 in the 2020-2021 Ligue 1 season from https://www.whoscored.com/Matches/1464126/Live/France-Ligue-1-2020-2021-Strasbourg-Reims\r"
     ]
    }
   ],
   "source": [
    "# Full season scraper\n",
    "\n",
    "## Define season and competition\n",
    "season = 2021\n",
    "comp = 'Ligue 1'\n",
    "\n",
    "## Scrape JSON data for an entire season and saved as a Python dictionary\n",
    "scrape_whoscored_season(season, comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e339d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full season scraper\n",
    "\n",
    "## Define season and competition\n",
    "season = 2020\n",
    "comp = 'Ligue 1'\n",
    "\n",
    "## Scrape JSON data for an entire season and saved as a Python dictionary\n",
    "scrape_whoscored_season(season, comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-passenger",
   "metadata": {},
   "source": [
    "##### <a id='#section3.2.1.1'>3.2.1.1. Premier League (EPL)\n",
    "First season available in WhoScored is the 09/10 season (`year` == 2010)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fcd1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full season scraper\n",
    "\n",
    "## Define season and competition\n",
    "season = 2022\n",
    "comp = 'EPL'\n",
    "\n",
    "## Scrape JSON data for an entire season and saved as a Python dictionary\n",
    "scrape_whoscored_season(season, comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4264ea",
   "metadata": {},
   "source": [
    "##### <a id='#section3.2.1.2'>3.2.1.2. Serie A\n",
    "First season available in WhoScored is the 09/10 season (`year` == 2010)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8622cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full season scraper\n",
    "\n",
    "## Define season and competition\n",
    "season = 2009\n",
    "comp = 'Serie A'\n",
    "\n",
    "## Scrape JSON data for an entire season and saved as a Python dictionary\n",
    "scrape_whoscored_season(season, comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-framing",
   "metadata": {},
   "source": [
    "##### <a id='#section3.2.1.3'>3.2.1.3. La Liga\n",
    "First season available in WhoScored is the 09/10 season (year == 2010)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a879f417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full season scraper\n",
    "\n",
    "## Define season and competition\n",
    "season = 2009\n",
    "comp = 'La Liga'\n",
    "\n",
    "## Scrape JSON data for an entire season and saved as a Python dictionary\n",
    "scrape_whoscored_season(season, comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-renewal",
   "metadata": {},
   "source": [
    "##### <a id='#section3.2.1.4'>3.2.1.4. Bundesliga\n",
    "First season available in WhoScored is the 09/10 season (year == 2010)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdb70e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full season scraper\n",
    "\n",
    "## Define season and competition\n",
    "season = 2019\n",
    "comp = 'Bundesliga'\n",
    "\n",
    "## Scrape JSON data for an entire season and saved as a Python dictionary\n",
    "json = scrape_whoscored_season(season, comp)\n",
    "\n",
    "## Display dictionary\n",
    "json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-distance",
   "metadata": {},
   "source": [
    "##### <a id='#section3.2.1.5'>3.2.1.5. Ligue 1\n",
    "First season available in WhoScored is the 09/10 season (year == 2010)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9568b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full season scraper\n",
    "\n",
    "## Define season and competition\n",
    "season = 2020\n",
    "comp = 'Ligue 1'\n",
    "\n",
    "## Scrape JSON data for an entire season and saved as a Python dictionary\n",
    "json = scrape_whoscored_season(season, comp)\n",
    "\n",
    "## Display dictionary\n",
    "json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-rough",
   "metadata": {},
   "source": [
    "##### <a id='#section3.2.1.6'>3.2.1.6. MLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2d547b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "informational-ghost",
   "metadata": {},
   "source": [
    "##### <a id='#section3.2.1.7'>3.2.1.7. Championship\n",
    "First season available in WhoScored is the 13/14 season (year == 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edcd09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full season scraper\n",
    "\n",
    "## Define season and competition\n",
    "season = 2021\n",
    "comp = \"EFL Championship\"\n",
    "\n",
    "## Scrape JSON data for an entire season and saved as a Python dictionary\n",
    "json = scrape_whoscored_season(season, comp)\n",
    "\n",
    "## Display dictionary\n",
    "json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf4ee7d",
   "metadata": {},
   "source": [
    "#### <a id='#section3.2.8'>3.2.8. League One\n",
    "First season available in WhoScored is the 13/14 season (year == 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43096e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full season scraper\n",
    "\n",
    "## Define season and competition\n",
    "season = 2014\n",
    "comp = \"EFL1\"\n",
    "\n",
    "## Scrape JSON data for an entire season and saved as a Python dictionary\n",
    "json = scrape_whoscored_season(season, comp)\n",
    "\n",
    "## Display dictionary\n",
    "json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d34bf5",
   "metadata": {},
   "source": [
    "#### <a id='#section3.2.9'>3.2.9. League Two\n",
    "First season available in WhoScored is the 13/14 season (year == 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479f817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full season scraper\n",
    "\n",
    "## Define season and competition\n",
    "season = 2021\n",
    "comp = \"EFL2\"\n",
    "\n",
    "## Scrape JSON data for an entire season and saved as a Python dictionary\n",
    "json = scrape_whoscored_season(season, comp)\n",
    "\n",
    "## Display dictionary\n",
    "json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f533fcb9",
   "metadata": {},
   "source": [
    "#### <a id='#section3.2.2'>3.2.2. Single Match Scraper\n",
    "Serie A for 21/22 season (`Year` == 2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f574de5",
   "metadata": {},
   "source": [
    "##### <a id='#section3.2.2.1'>3.2.2.1. Premier League (EPL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3308850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single match scraper\n",
    "\n",
    "## Define URL\n",
    "url = 'https://www.whoscored.com/Matches/1549687/Live/' + \\\n",
    "      'England-Premier-League-2021-2022-West-Ham-Chelsea'\n",
    "\n",
    "## Scrape JSON data for a single match and saved as a Python dictionary\n",
    "item = scrape_whoscored_match(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-shore",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='section4'></a>\n",
    "\n",
    "## <a id='#section4'>4. Summary</a>\n",
    "This notebook scrapes player statstics data from [WhoScored?](https://www.whoscored.com/) using [pandas](http://pandas.pydata.org/) for data manipulation through DataFrames, [Selenium](https://www.selenium.dev/) and [Beautifulsoup](https://pypi.org/project/beautifulsoup4/) for webscraping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-watch",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a id='section5'></a>\n",
    "\n",
    "## <a id='#section5'>5. Next Steps</a>\n",
    "This data is now ready to be engineered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-airfare",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a id='section6'></a>\n",
    "\n",
    "## <a id='#section6'>6. References</a>\n",
    "*    [ScraperFC](https://github.com/oseymour/ScraperFC) Opta event data webscraper for [WhoScored?](https://www.whoscored.com/) by [Owen Seymour](https://mobile.twitter.com/owen_seymour)\n",
    "*    [Owen Seymour](https://mobile.twitter.com/owen_seymour)'s Google Drive for data already scraped, including Premier League data since 09/10: \n",
    "https://drive.google.com/drive/folders/1LhW3wcG5uoAAHcgPHRcJYmIQaMY9GlRI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-tourism",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "***Visit my website [eddwebster.com](https://www.eddwebster.com) or my [GitHub Repository](https://github.com/eddwebster) for more projects. If you'd like to get in contact, my Twitter handle is [@eddwebster](http://www.twitter.com/eddwebster) and my email is: edd.j.webster@gmail.com.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-newcastle",
   "metadata": {},
   "source": [
    "[Back to the top](#top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
